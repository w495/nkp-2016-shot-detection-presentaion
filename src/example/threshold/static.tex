
\begin{frame}{Пороговые методы cо статическим порогом}
    \graybox{Как устроены}{
        \begin{itemize}
            \item разница соседних величин (по некоторой норме);
            \item превышения порога — <<аномалия>>.
        \end{itemize}%
    }
    \vspace{0.5em}
    \orangebox{Плюсы}{
        \begin{itemize}
            \item просты в реализации, втч аппаратной;
            \item не требовательны к ресурсам.
        \end{itemize}%
    }
    \vspace{0.5em}
    \bluebox{Минусы}{
        \begin{itemize}
            \item требуется заранее знать порог;
            \item не применимо для разных типов видео;
            \item чувствительны к случайным всплескам;
            \item ловят только краткосрочные события.
        \end{itemize}%
    }
\end{frame}

\subsubsection[Наивный метод]{Наивный пороговый метод: разница по модулю}

\begin{imageframe}{
    <<Дядя Стёпа~—~милиционер>>, наивный пороговый метод
 }
    \includegraphics[height=8.2cm]
    {img/video/example/threshold/static/sad-stepa.pdf}
\end{imageframe}


\begin{noteframe}
    В качестве исследуемой величины тут используется 
    значение нормированной попиксельной 
    абсолютной разницы яркостей двух соседних кадров.
    В качестве нормы используется векторная норма $L_1$.
    \[
        D_t            
            = \left\| F_t - F_{t-1} \right\|_{L_1} 
                = \dfrac{1}{n \cdot m} 
                    \sum\limits_{i=0}^{n}
                    \sum\limits_{j=0}^{m}
                        \left| x_{t,i,j} - x_{t-1,i,j} \right| 
    \]
    \begin{itemize}
        \item $x_{t,i,j}$ — пиксель кадра $F_t$;
        \item $x_{t-1,i,j}$ — пиксель кадра $F_{t-1}$;
    \end{itemize}
    Физический смысл этой величины 
    $\left| x_{t,i,j} - x_{t-1,i,j} \right|$
    заключается в том, насколько один пиксель отличается от другого.
\end{noteframe}
    

\begin{frame}[fragile]{Простой порог: Мета-язык потоковой обработки}
    \begin{lstlisting}[language=FilterPython]
    delay = DelayFilter()      # %{\cmnt Фильтр линейной задержки.}%
    orig  = delay(0)           # %{\cmnt Входящий сигнал без изменения.}%
    shift = ShiftSWFilter()    # %{\cmnt Сдвиг сигнала на один кадр.}%
    diff = orig - shift        # %{\cmnt Разница соседних кадров.}%
    norm = NormFilter()        # %{\cmnt Норма сигнала.}%
    modulus = ModulusFilter()  # %{\cmnt Модуль сигнала.}%
    T_CONST = 0.08             # %{\cmnt Значение порога. Константа.}%
    threshold = orig > T_CONST # %{\cmnt Пороговый фильтр.}%
    
    # %{\cmnt Фильтр нормированной попиксельной абсолютной разницы.}%
    d_filter = diff | modulus | norm(l=1)
    
    # %{\cmnt Результирующий фильтр: точки разладок.}%
    result_filter = d_filter | threshold
    \end{lstlisting}
    \begin{itemize}
        \item Оператор <<|>> означает <<конвейер>>.
        \item Фильтры собирается отложено 
                до непосредственного применения.
    \end{itemize}
\end{frame}

\begin{noteframe}
    Для решения задачи мы разработали мета-язык 
    на базе языка Python.\\
    Свойства мета-языка:
    \begin{enumerate}
        \item Основной сущностью является фильтр:
        \begin{itemize}
            \item по-факту это просто абстрактный тип 
            на языке Python с перегруженными операторвами,
            \item фильтры описывают набор действий 
            над последовательностью кадров видео;
        \end{itemize}
        \item Любые прочие объекты приводятся к фильтру и действия с ними осуществляются как с фильтром;
        \item Жизненный цикл фильтра состоит из двух этапов:
        \begin{itemize}
            \item объявление фильтра — при создании фильтра никаких вычислений над последовательностью кадров не происходит,
            \item выполнении фильтра —
            (вызов метода класса $filter\_objects$) 
            внутри фильтра происходит обработка 
            последовательности объектов: 
            кадров или результатов работы других фильтров;
        \end{itemize}
    \end{enumerate}
\end{noteframe}


\begin{noteframe}
    Операции над фильтрами:
    \begin{enumerate}
        \item Любая операция над фильтрами кроме выполнения,
        приводит к созданию нового фильтра:
        \begin{itemize}
            \item на этапе выполнения фильтра будут вычислены 
            аргументы этой операции и выполнена сама операция;
            \item порядок вычисления аргументов операций не определен, и на многоядерных архитектурах аргументы операций могут быть вычислены параллельно;
        \end{itemize}
        \item Основная операция над фильтрами — последовательное их применение — конвейер. Она тоже приводит к созданию нового фильтра.
        \item Прочие операции над фильтрами приводят 
        к изменению последовательности объектов или их свойств
        в процессе выполнения итогового фильтра.
    \end{enumerate}
\end{noteframe}



\subsubsection{FFmpeg}

\begin{imageframe}{
    <<Дядя Стёпа~—~милиционер>>, определение <<сцен>> как в FFmpeg
}
    \includegraphics[height=8.2cm]
    {img/video/example/threshold/static/ffmpeg-stepa.pdf}
    
\end{imageframe}


\begin{noteframe}
    FFmpeg — набор свободных библиотек, которые позволяют записывать, обрабатывать и передавать цифровое видео в различных форматах. 
    В том числе, FFmpeg содержит в себе возможность 
    выделения «сцен».
    
    В качестве исследуемой величины тут используется 
    значение наименьшей величины из двух:
    \begin{itemize}
        \item нормированной разницы яркостей двух соседних кадров;
        \item и абсолютной разницы двух последовательных разниц.
    \end{itemize}
    Такой минимум используется для того, чтобы избежать всплесков
    на случай если график сигнала монотонно убывает или возрастает.
    Разница двух последовательных разниц имеет смысл скорости 
    изменения яркости. Малая скорость изменения 
    при значительном изменении говорит о том, 
    что яркость равномерно меняется 
    в некоторой окрестности данного кадра.
    При быстром, но плавном изменении яркостей кадров 
    с точки зрения авторов порога из FFmpeg — разладки нет.
    
    Опишем алгоритм применяем в FFmpeg 
    с помощью нашего мета-языка потоковой обработки.
\end{noteframe}




\begin{frame}[fragile]{FFmpeg: Мета-язык потоковой обработки}
    \begin{lstlisting}[language=FilterPython]
    delay = DelayFilter()      # %{\cmnt Фильтр линейной задержки.}%
    orig  = delay(0)           # %{\cmnt Входящий сигнал без изменения.}%
    shift = ShiftSWFilter()    # %{\cmnt Сдвиг сигнала на один кадр.}%
    diff = orig - shift        # %{\cmnt Разница соседних кадров.}%
    norm = NormFilter()        # %{\cmnt Норма сигнала.}%
    modulus = ModulusFilter()  # %{\cmnt Модуль сигнала.}%
    T_CONST = 0.08             # %{\cmnt Значение порога. Константа.}%
    threshold = orig > T_CONST # %{\cmnt Пороговый фильтр.}%
    
    # %{\cmnt Фильтр нормированной попиксельной абсолютной разницы.}%
    d_filter = diff | modulus | norm(l=1)
    # %{\cmnt Абсолютная разница двух последовательных разниц.}%
    d_diff_filter = d_filter | diff | abs
    
    # %{\cmnt Минимум между разницей и разницей разниц.}%
    ffmpeg_like = Filter.union(d_filter, d_diff_filter) | min
    
    # %{\cmnt Результирующий фильтр: точки разладок.}%
    result_filter = ffmpeg_like | threshold
    \end{lstlisting}
\end{frame}

\begin{noteframe}
    В приведенном листинге применяется функция $Filter.union$.
    В качестве аргументов передаются фильтры, 
    и выходом функции тоже будет фильтр. 
    $Filter.union$ объединяет выходные последовательности (потоки)
    своих аргументов, так, что единица результирующей  последовательности функции $Filter.union$ содержит 
    в себе соответствующие единицы последовательности аргументов.
    Единицей последовательности в данном случае выступает 
    значение вычисляемой функции для текущего кадра.
    Последовательности аргументов должны быть 
    синхронизированы по времени.
    
    К результату функции $Filter.union$ применяется оператор $\min$.
    В контексте работы с фильтрами это означает, что оператор $\min$
    применяется к каждому элементу выходной последовательности.
    А это в свою очередь означает что будет 
    вычислен минимум двух величин.
    \[
        D_{t}^{ffmpeg} = \min(D_t, \left|D_t - D_{t-1} \right|)
    \]
\end{noteframe}


\begin{frame}[fragile]{FFmpeg: Примечание (1)}
    
    \begin{mgraybox}{ffmpeg\_like не совсем ffmpeg:}
        формула и результат совпадают с результатом FFmpeg, 
        с~точностью до~коэффициента $FFMPEG\_CORRECTION$.
    \end{mgraybox}

    \begin{lstlisting}[language=FilterPython]
    # %{\cmnt Минимум между разницей и разницей разниц.}%
    ffmpeg_like = Filter.union(d_filter, d_diff_filter) | min
    
    # %{\cmnt Коррекция возникает из-за того что в ffmpeg}% 
    # %{\cmnt цвета представляют целыми числами, без нормировки. }%
    COLOUR_CORRECTION = 3 * 256.0
    
    # %{\cmnt Нормировка взята из исходных кодов ffmpeg. }% 
    FFMPEG_NORM = 100.0
    
    FFMPEG_CORRECTION = COLOUR_CORRECTION / FFMPEG_NORM
    
    # %{\cmnt Как в настоящем FFmpeg.}%
    true_ffmpeg = ffmpeg_like | orig * FFMPEG_CORRECTION
    \end{lstlisting}
\end{frame}

\begin{frame}[fragile]{FFmpeg: Примечание (2)}
Точки линейных склеек «по FFmpeg» можно получить 
с помощью консольной команды:
\begin{lstlisting}[
    language=FFmpegBash,numbers=none
]
ffmpeg -i 'file.mp4' -filter:v "yadif=1:-1:0,select='gt(scene,0.4)',showinfo" -f 'null' -y 'qq' 2> >( grep 'pts_time' | sed -uE 's/.*n:\s*?([0-9]+).*pts:\s*?([0-9]+).*pts_time:\s*?([0-9\.]+).*pos:\s*?([0-9]+).*.*type:\s*?([IPB?]+).*.*mean:\s*?\[(.+)\].*.*stdev:\s*?\[(.+)\].*/n:\1\tpts_time:\3\t\tframe_type:\5\tmean:\6 std:\7/gi' | tee ./out/file-null.log 1>&2);
\end{lstlisting}
Вывод команды:
\begin{lstlisting}[basicstyle=\scriptsize\ttfamily,numbers=none]
    n: 0  pts_time: 8.279  frame_type:P  mean: 20  std:47.0 
    n: 1  pts_time:13.999  frame_type:B  mean: 40  std:71.3 
    n: 2  pts_time:14.159  frame_type:P  mean:180  std:75.7 
    n: 3  pts_time:14.719  frame_type:B  mean:183  std:69.7 
    n: 4  pts_time:14.759  frame_type:B  mean:179  std:70.6 
    n: 5  pts_time:18.319  frame_type:P  mean:187  std:73.2 
    n: 6  pts_time:28.999  frame_type:P  mean: 38  std:53.6 
    n: 7  pts_time:49.119  frame_type:P  mean: 27  std:46.0 
    n: 8  pts_time:61.399  frame_type:P  mean: 57  std:71.3 
    n: 9  pts_time:64.599  frame_type:P  mean: 38  std:58.4 
\end{lstlisting}
    
\end{frame}


\subsubsection{Сравнение порогов}

\begin{imageframe}{
    <<Дядя Стёпа~—~милиционер>>, сравнение порогов
}
    \includegraphics[height=8.2cm]
        {img/video/example/threshold/static/both-stepa.pdf}
\end{imageframe}




\begin{noteframe}
    Сравнивать изложенные методы удобно,
    если их вывести на одном графике. 
    В большинстве случаев для данного временного ряда 
    наивный пороговый метод и порог по FFmpeg совпадают.
    
    
    Исключение составляет участок с двадцатой по тридцатую секунды.
    В этом месте, наивный метод выявил значимую разницу.
    Порог по FFmpeg эту разницу не обнаружил:
    \begin{itemize}
        \item в первом случае, скорость изменения разницы 
        оказалась недостаточной:
        \begin{itemize}
            \item при приближении на графике отчетливо видно 
            пологий спуск.
        \end{itemize}
        \item во втором — не хватил величины порога.
    \end{itemize}
    С формальное точки зрения, алгоритм предложенный в FFmpeg,
    лучше наивного метода. Условие минимума разницы 
    и скорости изменения разница отсекает ложные срабатывания.
    Но в данном случае, много зависит от того что считать «разладкой».
\end{noteframe}

\begin{imageframe}{
        Сравнение порогов, секунды с 20 по 40
    }
    \includegraphics[height=8.2cm]
    {img/video/example/threshold/static/both-stepa-20-40.pdf}
\end{imageframe}


\subsubsection{Чем плох статический порог}



\begin{frame}{Чем плох статический порог}
    
    \bluebox{Что получилось:}{ 
        Для определения событий в~Съёмке с~БПЛА над~побережьем Тулума,
        порога $0.08$ не хватило.
        \begin{itemize}
            \item Все разницы кадров оказались меньше порога.
            \item События найдены не были.
        \end{itemize}
    }
    \vspace{1.5em}
    \orangebox{В чём проблема:}{
        \begin{itemize}
            \item величину порога надо знать заранее;
            \item нельзя использовать везде одну и ту же величину:
            \begin{itemize}
                \item в плавном видео — малые разницы кадров;
                \item в динамичном видео — большие разницы кадров.
            \end{itemize}
        \end{itemize}%
    }
\end{frame}

\begin{imageframe}{Съёмка с БПЛА над побережьем Тулума (Мексика)}
    \includegraphics[height=8.2cm]%
    {img/video/example/threshold/static/sad-tulum.pdf}
\end{imageframe}


\begin{frame}{Улучшения статического порога}
    \orangebox{Проблема:}{
        \begin{itemize}
        \item большой порог для плавного видео:
            \begin{itemize}
                \item события найдены не будут;
            \end{itemize}
        \item маленький порог для динамичного видео:
            \begin{itemize}
                \item много ложных срабатываний;
            \end{itemize}
        \item если видео имеет плавные и динамичные участки:
            \begin{itemize}
                \item порог подобрать невозможно.
            \end{itemize}
        \end{itemize}
    }
    \vspace{1.5em}
    \greenbox{Решение:}{
        \begin{itemize}
            \item Учитывать «динамичность» видео:
            \begin{enumerate}
                \item Масштабировать разницы кадров:
                \begin{itemize}
                    \item нормировать по окрестности.
                \end{itemize}
                \item Учитывать среднюю величину и дисперсию.
            \end{enumerate}
        \end{itemize}
    }
\end{frame}



\begin{frame}{Масштабировать разницы кадров}


\[
    Norm_{n} = \dfrac
    {F_{t} - \min \left(  F_{t-n} \dots  F_{t} \right)}
    {\max \left( F_{t-n} \dots  F_{t} \right)
        - \min \left( F_{t-n} \dots  F_{t} \right)}
\]    
\end{frame}



\begin{frame}[fragile]{Масштабировать разницы кадров: Мета-язык}
\begin{footnotesize} 
Мета-язык на базе языка Python.
\end{footnotesize}
\begin{lstlisting}[language=FilterPython]
delay = DelayFilter()      # %{\cmnt Фильтр линейной задержки.}%
orig  = delay(0)           # %{\cmnt Входящий сигнал без изменения.}%
shift = ShiftSWFilter()    # %{\cmnt Сдвиг сигнала на один кадр.}%
diff = orig - shift        # %{\cmnt Разница соседних кадров.}%
norm = NormFilter()        # %{\cmnt Норма сигнала.}%
modulus = ModulusFilter()  # %{\cmnt Модуль сигнала.}%

# %{\cmnt Возвращает скользящее окно размер 200 для каждого кадра}%
sw = BaseSWFilter(s=200, min_size=2)

swmax = sw | max  # %{\cmnt Максимум по скользящему окну.}%
swmin = sw | min  # %{\cmnt Минимум по скользящему окну.}%

swnorm = (orig - swmin) / (swmax - swmin) # %{\cmnt Масштабирование.}%

# %{\cmnt Результирующий фильтр}%
result_filter = norm(l=1) | diff | modulus | swnorm
\end{lstlisting}
\end{frame}

\note{
Для решения задачи мы разработали мета-язык на базе языка Python.
Фильтры собирается отложено до непосредственного применения.
Оператор <<|>> означает <<конвейер>>.
}

\begin{imageframe}{
Съёмка с БПЛА над побережьем Тулума,
масштабированный простой порог
}
    \includegraphics[height=8.2cm]%
    {img/video/example/threshold/static/sad-swnorm-200-tulum.pdf}
\end{imageframe}

